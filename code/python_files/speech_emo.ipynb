{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICSigSys4: Speech emotion recognition using voiced speech and local attention\n",
    "by Bagus Tris Atmaja (bagus@jaist.ac.jp)  \n",
    "\n",
    "In this paper we compare the following model for speech emotion recognition:\n",
    "1. Raw speech, using 2 stack Bidirectional LSTM\n",
    "2. Voiced speech only, using 2 stack Bidirectional LSTM\n",
    "3. Raw speech, using 2 stack Bidirectional LSTM and attention model\n",
    "4. Voiced speech, using 2 stack Bidirectional LSTM and attention model\n",
    "\n",
    "For silence removal, we evaluate the following variations:\n",
    "- Effect of various minimum sample duration for silence: 0.001, 0.006, 0.01 s\n",
    "- Effect of various minimum threshold for silence to be removed: 0.001, 0.007, 0.01 %\n",
    "\n",
    "that lead 0.001 minimum duration and 0.001 of threshold giving the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import needed module, unimport unneeded moduld\n",
    "import numpy as np\n",
    "from tensorflow import set_random_seed\n",
    "import matplotlib.pyplot as plt\n",
    "import audiosegment\n",
    "import sounddevice as sd\n",
    "from features import *\n",
    "from helper import *\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import signal\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import wave\n",
    "import copy\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input, Flatten, Embedding, Conv1D, Conv2D, Dropout, MaxPooling2D, Bidirectional\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "set_random_seed(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir path for the data\n",
    "code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n",
    "data_path = \"/media/bagus/data01/dataset/IEMOCAP_full_release/\"\n",
    "sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n",
    "framerate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read already saved pickle data\n",
    "import pickle\n",
    "with open(data_path +'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calc feature\n",
    "\n",
    "def calculate_features(frames, freq, options):\n",
    "    window_sec = 0.2\n",
    "    window_n = int(freq * window_sec)\n",
    "\n",
    "    st_f = stFeatureExtraction(frames, freq, window_n, window_n / 2)\n",
    "\n",
    "    if st_f.shape[1] > 2:\n",
    "        i0 = 1\n",
    "        i1 = st_f.shape[1] - 1\n",
    "        if i1 - i0 < 1:\n",
    "            i1 = i0 + 1\n",
    "        \n",
    "        deriv_st_f = np.zeros((st_f.shape[0], i1 - i0), dtype=float)\n",
    "        for i in range(i0, i1):\n",
    "            i_left = i - 1\n",
    "            i_right = i + 1\n",
    "            deriv_st_f[:st_f.shape[0], i - i0] = st_f[:, i]\n",
    "        return deriv_st_f\n",
    "    elif st_f.shape[1] == 2:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f\n",
    "    else:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read speech signal from variable data2\n",
    "x_train_speech = np.load('voiced_feat_without_sil_removal.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read output label\n",
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = label_binarize(Y,emotions_used)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1\n",
    "def speech_model1():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(100, 34)))\n",
    "    model.add(LSTM(256, return_sequences=False))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 512)          1120256   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,041,348\n",
      "Trainable params: 2,041,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = speech_model1()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3307 samples, validate on 1629 samples\n",
      "Epoch 1/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0582 - acc: 0.9831 - val_loss: 3.8061 - val_acc: 0.5629\n",
      "Epoch 2/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0641 - acc: 0.9825 - val_loss: 3.7052 - val_acc: 0.5574\n",
      "Epoch 3/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0383 - acc: 0.9894 - val_loss: 3.6128 - val_acc: 0.5494\n",
      "Epoch 4/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0659 - acc: 0.9834 - val_loss: 4.1769 - val_acc: 0.5445\n",
      "Epoch 5/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0834 - acc: 0.9791 - val_loss: 3.5950 - val_acc: 0.5568\n",
      "Epoch 6/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0585 - acc: 0.9876 - val_loss: 3.6311 - val_acc: 0.5427\n",
      "Epoch 7/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0573 - acc: 0.9834 - val_loss: 3.7009 - val_acc: 0.5537\n",
      "Epoch 8/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0619 - acc: 0.9837 - val_loss: 3.8587 - val_acc: 0.5770\n",
      "Epoch 9/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0710 - acc: 0.9816 - val_loss: 4.0386 - val_acc: 0.5396\n",
      "Epoch 10/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0628 - acc: 0.9831 - val_loss: 3.8385 - val_acc: 0.5599\n",
      "Epoch 11/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0559 - acc: 0.9861 - val_loss: 4.0759 - val_acc: 0.5629\n",
      "Epoch 12/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0749 - acc: 0.9831 - val_loss: 3.9197 - val_acc: 0.5562\n",
      "Epoch 13/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0515 - acc: 0.9852 - val_loss: 4.1742 - val_acc: 0.5457\n",
      "Epoch 14/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0593 - acc: 0.9846 - val_loss: 3.3269 - val_acc: 0.5580\n",
      "Epoch 15/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0651 - acc: 0.9858 - val_loss: 3.8091 - val_acc: 0.5488\n",
      "Epoch 16/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0671 - acc: 0.9809 - val_loss: 3.8347 - val_acc: 0.5347\n",
      "Epoch 17/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0570 - acc: 0.9870 - val_loss: 3.7425 - val_acc: 0.5506\n",
      "Epoch 18/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0580 - acc: 0.9849 - val_loss: 3.9881 - val_acc: 0.5592\n",
      "Epoch 19/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0652 - acc: 0.9849 - val_loss: 3.5984 - val_acc: 0.5562\n",
      "Epoch 20/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0406 - acc: 0.9882 - val_loss: 4.0359 - val_acc: 0.5421\n",
      "Epoch 21/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0482 - acc: 0.9882 - val_loss: 4.1852 - val_acc: 0.5408\n",
      "Epoch 22/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0757 - acc: 0.9809 - val_loss: 3.4968 - val_acc: 0.5709\n",
      "Epoch 23/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0603 - acc: 0.9843 - val_loss: 3.9751 - val_acc: 0.5396\n",
      "Epoch 24/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0637 - acc: 0.9849 - val_loss: 4.1668 - val_acc: 0.5353\n",
      "Epoch 25/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0690 - acc: 0.9849 - val_loss: 3.5937 - val_acc: 0.5617\n",
      "Epoch 26/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0478 - acc: 0.9873 - val_loss: 3.8483 - val_acc: 0.5519\n",
      "Epoch 27/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0421 - acc: 0.9894 - val_loss: 4.0645 - val_acc: 0.5482\n",
      "Epoch 28/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0760 - acc: 0.9846 - val_loss: 3.7117 - val_acc: 0.5463\n",
      "Epoch 29/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0550 - acc: 0.9846 - val_loss: 4.3730 - val_acc: 0.5635\n",
      "Epoch 30/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0527 - acc: 0.9870 - val_loss: 4.4669 - val_acc: 0.5365\n",
      "Epoch 31/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0891 - acc: 0.9791 - val_loss: 3.8696 - val_acc: 0.5537\n",
      "Epoch 32/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0459 - acc: 0.9897 - val_loss: 3.9885 - val_acc: 0.5568\n",
      "Epoch 33/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0585 - acc: 0.9867 - val_loss: 4.3274 - val_acc: 0.5285\n",
      "Epoch 34/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0696 - acc: 0.9846 - val_loss: 4.2201 - val_acc: 0.5144\n",
      "Epoch 35/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0694 - acc: 0.9803 - val_loss: 3.6733 - val_acc: 0.5513\n",
      "Epoch 36/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0429 - acc: 0.9882 - val_loss: 4.1566 - val_acc: 0.5494\n",
      "Epoch 37/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0694 - acc: 0.9828 - val_loss: 4.0937 - val_acc: 0.5396\n",
      "Epoch 38/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0398 - acc: 0.9885 - val_loss: 4.5939 - val_acc: 0.5328\n",
      "Epoch 39/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0592 - acc: 0.9840 - val_loss: 3.6444 - val_acc: 0.5421\n",
      "Epoch 40/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0450 - acc: 0.9906 - val_loss: 4.3630 - val_acc: 0.5599\n",
      "Epoch 41/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0547 - acc: 0.9864 - val_loss: 3.7863 - val_acc: 0.5586\n",
      "Epoch 42/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0391 - acc: 0.9885 - val_loss: 4.1369 - val_acc: 0.5488\n",
      "Epoch 43/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0471 - acc: 0.9882 - val_loss: 3.9056 - val_acc: 0.5599\n",
      "Epoch 44/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0586 - acc: 0.9819 - val_loss: 3.6408 - val_acc: 0.5525\n",
      "Epoch 45/50\n",
      "3307/3307 [==============================] - 30s 9ms/step - loss: 0.0386 - acc: 0.9888 - val_loss: 4.0393 - val_acc: 0.5359\n",
      "Epoch 46/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0360 - acc: 0.9903 - val_loss: 4.0220 - val_acc: 0.5513\n",
      "Epoch 47/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0527 - acc: 0.9852 - val_loss: 3.7964 - val_acc: 0.5457\n",
      "Epoch 48/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0437 - acc: 0.9906 - val_loss: 3.9234 - val_acc: 0.5660\n",
      "Epoch 49/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0553 - acc: 0.9873 - val_loss: 3.9440 - val_acc: 0.5439\n",
      "Epoch 50/50\n",
      "3307/3307 [==============================] - 29s 9ms/step - loss: 0.0377 - acc: 0.9903 - val_loss: 4.1207 - val_acc: 0.5543\n"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "hist = model1.fit(x_train_speech, Y, batch_size=32, epochs=50, verbose=1, shuffle=False,\n",
    "                 validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5499693062625244 0.5770411293626636\n"
     ]
    }
   ],
   "source": [
    "acc1 = hist.history['val_acc']\n",
    "print(np.mean(acc1), max(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doing silence removal (already saved as npy)\n",
    "# voiced_feat = []\n",
    "# for ses_mod in data2:\n",
    "#     x_head = ses_mod['signal']\n",
    "#     seg = audiosegment.from_numpy_array(x_head, framerate)\n",
    "#     voice = seg.filter_silence(0.01, 0.1)\n",
    "#     st_features = calculate_features(voice.to_numpy_array(), framerate, None)\n",
    "#     st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "#     voiced_feat.append( st_features.T )\n",
    "#     #print(i)\n",
    "    \n",
    "# voiced_feat = np.array(voiced_feat)\n",
    "# voiced_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "voiced_feat = np.load('voiced_feat_file_001_001.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3307 samples, validate on 1629 samples\n",
      "Epoch 1/50\n",
      "3307/3307 [==============================] - 53s 16ms/step - loss: 0.0710 - acc: 0.9782 - val_loss: 3.1209 - val_acc: 0.5697\n",
      "Epoch 2/50\n",
      "3307/3307 [==============================] - 57s 17ms/step - loss: 0.0919 - acc: 0.9743 - val_loss: 3.3989 - val_acc: 0.5697\n",
      "Epoch 3/50\n",
      "3307/3307 [==============================] - 53s 16ms/step - loss: 0.0860 - acc: 0.9737 - val_loss: 3.2052 - val_acc: 0.5820\n",
      "Epoch 4/50\n",
      "3307/3307 [==============================] - 57s 17ms/step - loss: 0.0969 - acc: 0.9755 - val_loss: 3.3356 - val_acc: 0.5353\n",
      "Epoch 5/50\n",
      "3307/3307 [==============================] - 54s 16ms/step - loss: 0.0892 - acc: 0.9713 - val_loss: 3.0299 - val_acc: 0.5666\n",
      "Epoch 6/50\n",
      "3307/3307 [==============================] - 57s 17ms/step - loss: 0.0810 - acc: 0.9767 - val_loss: 2.9335 - val_acc: 0.5684\n",
      "Epoch 7/50\n",
      "3307/3307 [==============================] - 53s 16ms/step - loss: 0.0529 - acc: 0.9813 - val_loss: 3.4897 - val_acc: 0.5623\n",
      "Epoch 8/50\n",
      "3307/3307 [==============================] - 57s 17ms/step - loss: 0.0959 - acc: 0.9728 - val_loss: 3.1771 - val_acc: 0.5740\n",
      "Epoch 9/50\n",
      "3307/3307 [==============================] - 52s 16ms/step - loss: 0.0832 - acc: 0.9770 - val_loss: 2.8597 - val_acc: 0.5801\n",
      "Epoch 10/50\n",
      "3307/3307 [==============================] - 57s 17ms/step - loss: 0.0807 - acc: 0.9773 - val_loss: 3.0991 - val_acc: 0.5727\n",
      "Epoch 11/50\n",
      "3307/3307 [==============================] - 54s 16ms/step - loss: 0.0707 - acc: 0.9806 - val_loss: 3.3614 - val_acc: 0.5734\n",
      "Epoch 12/50\n",
      "3307/3307 [==============================] - 40s 12ms/step - loss: 0.0803 - acc: 0.9761 - val_loss: 3.0507 - val_acc: 0.5734\n",
      "Epoch 13/50\n",
      "3307/3307 [==============================] - 36s 11ms/step - loss: 0.0865 - acc: 0.9746 - val_loss: 3.1249 - val_acc: 0.5783\n",
      "Epoch 14/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.1030 - acc: 0.9755 - val_loss: 3.4865 - val_acc: 0.5574\n",
      "Epoch 15/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0678 - acc: 0.9809 - val_loss: 3.0801 - val_acc: 0.5709\n",
      "Epoch 16/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0942 - acc: 0.9785 - val_loss: 2.9601 - val_acc: 0.5838\n",
      "Epoch 17/50\n",
      "3307/3307 [==============================] - 36s 11ms/step - loss: 0.0803 - acc: 0.9776 - val_loss: 3.3277 - val_acc: 0.5549\n",
      "Epoch 18/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0773 - acc: 0.9803 - val_loss: 3.2223 - val_acc: 0.5592\n",
      "Epoch 19/50\n",
      "3307/3307 [==============================] - 50s 15ms/step - loss: 0.0783 - acc: 0.9755 - val_loss: 3.4089 - val_acc: 0.5549\n",
      "Epoch 20/50\n",
      "3307/3307 [==============================] - 56s 17ms/step - loss: 0.0641 - acc: 0.9816 - val_loss: 3.7311 - val_acc: 0.5574\n",
      "Epoch 21/50\n",
      "3307/3307 [==============================] - 53s 16ms/step - loss: 0.0797 - acc: 0.9785 - val_loss: 3.1964 - val_acc: 0.5697\n",
      "Epoch 22/50\n",
      "3307/3307 [==============================] - 54s 16ms/step - loss: 0.0691 - acc: 0.9837 - val_loss: 3.3646 - val_acc: 0.5721\n",
      "Epoch 23/50\n",
      "3307/3307 [==============================] - 57s 17ms/step - loss: 0.0726 - acc: 0.9822 - val_loss: 3.4403 - val_acc: 0.5887\n",
      "Epoch 24/50\n",
      "3307/3307 [==============================] - 53s 16ms/step - loss: 0.1131 - acc: 0.9725 - val_loss: 2.8775 - val_acc: 0.5758\n",
      "Epoch 25/50\n",
      "3307/3307 [==============================] - 57s 17ms/step - loss: 0.0667 - acc: 0.9816 - val_loss: 3.1193 - val_acc: 0.5586\n",
      "Epoch 26/50\n",
      "3307/3307 [==============================] - 53s 16ms/step - loss: 0.0653 - acc: 0.9816 - val_loss: 3.4068 - val_acc: 0.5513\n",
      "Epoch 27/50\n",
      "3307/3307 [==============================] - 56s 17ms/step - loss: 0.0654 - acc: 0.9785 - val_loss: 3.3486 - val_acc: 0.5752\n",
      "Epoch 28/50\n",
      "3307/3307 [==============================] - 53s 16ms/step - loss: 0.0749 - acc: 0.9791 - val_loss: 3.2045 - val_acc: 0.5770\n",
      "Epoch 29/50\n",
      "3307/3307 [==============================] - 40s 12ms/step - loss: 0.0767 - acc: 0.9791 - val_loss: 3.4091 - val_acc: 0.5734\n",
      "Epoch 30/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0577 - acc: 0.9816 - val_loss: 3.3127 - val_acc: 0.5543\n",
      "Epoch 31/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0525 - acc: 0.9840 - val_loss: 3.6345 - val_acc: 0.5635\n",
      "Epoch 32/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0752 - acc: 0.9782 - val_loss: 3.3301 - val_acc: 0.5592\n",
      "Epoch 33/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0643 - acc: 0.9831 - val_loss: 3.7100 - val_acc: 0.5488\n",
      "Epoch 34/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0608 - acc: 0.9846 - val_loss: 3.6138 - val_acc: 0.5568\n",
      "Epoch 35/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0651 - acc: 0.9791 - val_loss: 3.5144 - val_acc: 0.5611\n",
      "Epoch 36/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0627 - acc: 0.9840 - val_loss: 3.8386 - val_acc: 0.5605\n",
      "Epoch 37/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0588 - acc: 0.9831 - val_loss: 3.5779 - val_acc: 0.5697\n",
      "Epoch 38/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0577 - acc: 0.9800 - val_loss: 3.6683 - val_acc: 0.5617\n",
      "Epoch 39/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0904 - acc: 0.9761 - val_loss: 3.4430 - val_acc: 0.5660\n",
      "Epoch 40/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0740 - acc: 0.9782 - val_loss: 3.4370 - val_acc: 0.5746\n",
      "Epoch 41/50\n",
      "3307/3307 [==============================] - 36s 11ms/step - loss: 0.0568 - acc: 0.9873 - val_loss: 3.9038 - val_acc: 0.5482\n",
      "Epoch 42/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0624 - acc: 0.9809 - val_loss: 3.5532 - val_acc: 0.5470\n",
      "Epoch 43/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0735 - acc: 0.9816 - val_loss: 3.5690 - val_acc: 0.5592\n",
      "Epoch 44/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0508 - acc: 0.9825 - val_loss: 4.0944 - val_acc: 0.5599\n",
      "Epoch 45/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.1016 - acc: 0.9713 - val_loss: 3.4118 - val_acc: 0.5727\n",
      "Epoch 46/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0515 - acc: 0.9837 - val_loss: 3.6454 - val_acc: 0.5648\n",
      "Epoch 47/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0381 - acc: 0.9891 - val_loss: 3.6020 - val_acc: 0.5592\n",
      "Epoch 48/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0652 - acc: 0.9867 - val_loss: 3.6635 - val_acc: 0.5494\n",
      "Epoch 49/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0650 - acc: 0.9846 - val_loss: 4.0562 - val_acc: 0.5519\n",
      "Epoch 50/50\n",
      "3307/3307 [==============================] - 35s 11ms/step - loss: 0.0624 - acc: 0.9846 - val_loss: 3.5434 - val_acc: 0.5562\n"
     ]
    }
   ],
   "source": [
    "# trained model on model2 = voiced speech\n",
    "hist2 = model1.fit(voiced_feat, Y, batch_size=32, epochs=50, verbose=1, shuffle=False,\n",
    "                 validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5646163289661492 0.5887047270641069\n"
     ]
    }
   ],
   "source": [
    "acc2 = hist2.history['val_acc']\n",
    "print(np.mean(acc2), max(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder attention function for model3\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers, constraints, initializers, activations\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
    "\n",
    "def _time_distributed_dense(x, w, b=None, dropout=None,\n",
    "                           input_dim=None, output_dim=None,\n",
    "                           timesteps=None, training=None):\n",
    "    \"\"\"Apply `y . w + b` for every temporal slice y of x.\n",
    "    # Arguments\n",
    "    x: input tensor.\n",
    "    w: weight matrix.\n",
    "    b: optional bias vector.\n",
    "    dropout: wether to apply dropout (same dropout mask\n",
    "        for every temporal slice of the input).\n",
    "        input_dim: integer; optional dimensionality of the input.\n",
    "        output_dim: integer; optional dimensionality of the output.\n",
    "        timesteps: integer; optional number of timesteps.\n",
    "        training: training phase tensor or boolean.\n",
    "        # Returns\n",
    "            Output tensor.\n",
    "    \"\"\"\n",
    "    if not input_dim:\n",
    "        input_dim = K.shape(x)[2]\n",
    "    if not timesteps:\n",
    "        timesteps = K.shape(x)[1]\n",
    "    if not output_dim:\n",
    "        output_dim = K.shape(w)[1]\n",
    "    if dropout is not None and 0. < dropout < 1.:\n",
    "        # apply the same dropout pattern at every timestep\n",
    "        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
    "        dropout_matrix = K.dropout(ones, dropout)\n",
    "        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
    "        x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)\n",
    "    # collapse time dimension and batch dimension together\n",
    "    x = K.reshape(x, (-1, input_dim))\n",
    "    x = K.dot(x, w)\n",
    "    if b is not None:\n",
    "        x = K.bias_add(x, b)\n",
    "    # reshape to 3D tensor\n",
    "    if K.backend() == 'tensorflow':\n",
    "        x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n",
    "        x.set_shape([None, None, output_dim])\n",
    "    else:\n",
    "        x = K.reshape(x, (-1, timesteps, output_dim))\n",
    "    return x\n",
    "    \n",
    "class AttentionDecoder(Recurrent):\n",
    "    def __init__(self, units, output_dim,\n",
    "                 activation='tanh',\n",
    "                 return_probabilities=False,\n",
    "                 name='AttentionDecoder',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
    "        encoder and outputs the decoded states\n",
    "        :param units: dimension of the hidden state and the attention matrices\n",
    "        :param output_dim: the number of labels in the output space\n",
    "\n",
    "        references:\n",
    "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n",
    "            \"Neural machine translation by jointly learning to align and translate.\"\n",
    "            arXiv preprint arXiv:1409.0473 (2014).\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.output_dim = output_dim\n",
    "        self.return_probabilities = return_probabilities\n",
    "        self.activation = activations.get(activation)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.return_sequences = True  # must return sequences\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
    "          for model details that correspond to the matrices here.\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
    "\n",
    "        if self.stateful:\n",
    "            super(AttentionDecoder, self).reset_states()\n",
    "\n",
    "        self.states = [None, None]  # y, s\n",
    "\n",
    "        \"\"\"\n",
    "            Matrices for creating the context vector\n",
    "        \"\"\"\n",
    "\n",
    "        self.V_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='V_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='W_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='U_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.b_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='b_a',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for the r (reset) gate\n",
    "        \"\"\"\n",
    "        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_r = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_r = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_r',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        \"\"\"\n",
    "            Matrices for the z (update) gate\n",
    "        \"\"\"\n",
    "        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_z = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_z = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_z',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for the proposal\n",
    "        \"\"\"\n",
    "        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_p = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_p = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_p',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for making the final prediction vector\n",
    "        \"\"\"\n",
    "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
    "                                   name='C_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
    "                                   name='U_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
    "                                   name='W_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
    "                                   name='b_o',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        # For creating the initial state:\n",
    "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='W_s',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "\n",
    "        self.input_spec = [\n",
    "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
    "        self.x_seq = x\n",
    "\n",
    "        # apply the a dense layer over the time dimension of the sequence\n",
    "        # do it here because it doesn't depend on any previous steps\n",
    "        # thefore we can save computation time:\n",
    "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
    "                                             input_dim=self.input_dim,\n",
    "                                             timesteps=self.timesteps,\n",
    "                                             output_dim=self.units)\n",
    "\n",
    "        return super(AttentionDecoder, self).call(x)\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # apply the matrix on the first time step to get the initial s0.\n",
    "        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
    "\n",
    "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
    "        # output_dim)\n",
    "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
    "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
    "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
    "        y0 = K.tile(y0, [1, self.output_dim])\n",
    "\n",
    "        return [y0, s0]\n",
    "\n",
    "    def step(self, x, states):\n",
    "\n",
    "        ytm, stm = states\n",
    "\n",
    "        # repeat the hidden state to the length of the sequence\n",
    "        _stm = K.repeat(stm, self.timesteps)\n",
    "\n",
    "        # now multiplty the weight matrix with the repeated hidden state\n",
    "        _Wxstm = K.dot(_stm, self.W_a)\n",
    "\n",
    "        # calculate the attention probabilities\n",
    "        # this relates how much other timesteps contributed to this one.\n",
    "        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n",
    "                   K.expand_dims(self.V_a))\n",
    "        at = K.exp(et)\n",
    "        at_sum = K.sum(at, axis=1)\n",
    "        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n",
    "        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n",
    "\n",
    "        # calculate the context vector\n",
    "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "        # ~~~> calculate new hidden state\n",
    "        # first calculate the \"r\" gate:\n",
    "\n",
    "        rt = activations.sigmoid(\n",
    "            K.dot(ytm, self.W_r)\n",
    "            + K.dot(stm, self.U_r)\n",
    "            + K.dot(context, self.C_r)\n",
    "            + self.b_r)\n",
    "\n",
    "        # now calculate the \"z\" gate\n",
    "        zt = activations.sigmoid(\n",
    "            K.dot(ytm, self.W_z)\n",
    "            + K.dot(stm, self.U_z)\n",
    "            + K.dot(context, self.C_z)\n",
    "            + self.b_z)\n",
    "\n",
    "        # calculate the proposal hidden state:\n",
    "        s_tp = activations.tanh(\n",
    "            K.dot(ytm, self.W_p)\n",
    "            + K.dot((rt * stm), self.U_p)\n",
    "            + K.dot(context, self.C_p)\n",
    "            + self.b_p)\n",
    "\n",
    "        # new hidden state:\n",
    "        st = (1-zt)*stm + zt * s_tp\n",
    "\n",
    "        yt = activations.softmax(\n",
    "            K.dot(ytm, self.W_o)\n",
    "            + K.dot(stm, self.U_o)\n",
    "            + K.dot(context, self.C_o)\n",
    "            + self.b_o)\n",
    "\n",
    "        if self.return_probabilities:\n",
    "            return at, [yt, st]\n",
    "        else:\n",
    "            return yt, [yt, st]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"\n",
    "            For Keras internal compatability checking\n",
    "        \"\"\"\n",
    "        if self.return_probabilities:\n",
    "            return (None, self.timesteps, self.timesteps)\n",
    "        else:\n",
    "            return (None, self.timesteps, self.output_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "            For rebuilding models on load time.\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'units': self.units,\n",
    "            'return_probabilities': self.return_probabilities\n",
    "        }\n",
    "        base_config = super(AttentionDecoder, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 100, 512)          595968    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 256)          1082880   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               13107712  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 14,788,612\n",
      "Trainable params: 14,788,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model3 attention based\n",
    "def attention_model(optimizer='rmsprop'):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=(100, 34)))\n",
    "    model.add(Bidirectional(AttentionDecoder(128, 128)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model3 = attention_model()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3307 samples, validate on 1629 samples\n",
      "Epoch 1/50\n",
      "3307/3307 [==============================] - 114s 34ms/step - loss: 0.0942 - acc: 0.9822 - val_loss: 3.5544 - val_acc: 0.6433\n",
      "Epoch 2/50\n",
      "3307/3307 [==============================] - 116s 35ms/step - loss: 0.0961 - acc: 0.9831 - val_loss: 3.4767 - val_acc: 0.6476\n",
      "Epoch 3/50\n",
      "3307/3307 [==============================] - 116s 35ms/step - loss: 0.1026 - acc: 0.9813 - val_loss: 3.3323 - val_acc: 0.6341\n",
      "Epoch 4/50\n",
      "3307/3307 [==============================] - 106s 32ms/step - loss: 0.0698 - acc: 0.9855 - val_loss: 4.0059 - val_acc: 0.6390\n",
      "Epoch 5/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1158 - acc: 0.9837 - val_loss: 4.3316 - val_acc: 0.6298\n",
      "Epoch 6/50\n",
      "3307/3307 [==============================] - 81s 24ms/step - loss: 0.1136 - acc: 0.9752 - val_loss: 3.1634 - val_acc: 0.6335\n",
      "Epoch 7/50\n",
      "3307/3307 [==============================] - 85s 26ms/step - loss: 0.0865 - acc: 0.9788 - val_loss: 3.1830 - val_acc: 0.6495\n",
      "Epoch 8/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0786 - acc: 0.9843 - val_loss: 4.5928 - val_acc: 0.6053\n",
      "Epoch 9/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0921 - acc: 0.9855 - val_loss: 3.2805 - val_acc: 0.6581\n",
      "Epoch 10/50\n",
      "3307/3307 [==============================] - 85s 26ms/step - loss: 0.1275 - acc: 0.9764 - val_loss: 2.7678 - val_acc: 0.6507\n",
      "Epoch 11/50\n",
      "3307/3307 [==============================] - 84s 26ms/step - loss: 0.1011 - acc: 0.9816 - val_loss: 3.1089 - val_acc: 0.6446\n",
      "Epoch 12/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0851 - acc: 0.9831 - val_loss: 3.3262 - val_acc: 0.6501\n",
      "Epoch 13/50\n",
      "3307/3307 [==============================] - 84s 26ms/step - loss: 0.1095 - acc: 0.9816 - val_loss: 3.4311 - val_acc: 0.6495\n",
      "Epoch 14/50\n",
      "3307/3307 [==============================] - 85s 26ms/step - loss: 0.0846 - acc: 0.9819 - val_loss: 3.2846 - val_acc: 0.6329\n",
      "Epoch 15/50\n",
      "3307/3307 [==============================] - 85s 26ms/step - loss: 0.0579 - acc: 0.9885 - val_loss: 4.0042 - val_acc: 0.6274\n",
      "Epoch 16/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1156 - acc: 0.9794 - val_loss: 3.5317 - val_acc: 0.6366\n",
      "Epoch 17/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1189 - acc: 0.9746 - val_loss: 3.4851 - val_acc: 0.6433\n",
      "Epoch 18/50\n",
      "3307/3307 [==============================] - 84s 26ms/step - loss: 0.0575 - acc: 0.9888 - val_loss: 3.6235 - val_acc: 0.6495\n",
      "Epoch 19/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0676 - acc: 0.9852 - val_loss: 3.5623 - val_acc: 0.6458\n",
      "Epoch 20/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0902 - acc: 0.9843 - val_loss: 3.7595 - val_acc: 0.6194\n",
      "Epoch 21/50\n",
      "3307/3307 [==============================] - 85s 26ms/step - loss: 0.1008 - acc: 0.9776 - val_loss: 3.4670 - val_acc: 0.6378\n",
      "Epoch 22/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0679 - acc: 0.9840 - val_loss: 3.3382 - val_acc: 0.6483\n",
      "Epoch 23/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0676 - acc: 0.9840 - val_loss: 3.3512 - val_acc: 0.6544\n",
      "Epoch 24/50\n",
      "3307/3307 [==============================] - 84s 26ms/step - loss: 0.0775 - acc: 0.9840 - val_loss: 3.9006 - val_acc: 0.6323\n",
      "Epoch 25/50\n",
      "3307/3307 [==============================] - 85s 26ms/step - loss: 0.0847 - acc: 0.9855 - val_loss: 3.3841 - val_acc: 0.6568\n",
      "Epoch 26/50\n",
      "3307/3307 [==============================] - 84s 26ms/step - loss: 0.0678 - acc: 0.9882 - val_loss: 3.6503 - val_acc: 0.6470\n",
      "Epoch 27/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1130 - acc: 0.9828 - val_loss: 3.5688 - val_acc: 0.6440\n",
      "Epoch 28/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0713 - acc: 0.9852 - val_loss: 3.7175 - val_acc: 0.6440\n",
      "Epoch 29/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1008 - acc: 0.9806 - val_loss: 3.2314 - val_acc: 0.6440\n",
      "Epoch 30/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1237 - acc: 0.9782 - val_loss: 3.6184 - val_acc: 0.6354\n",
      "Epoch 31/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0658 - acc: 0.9876 - val_loss: 4.0872 - val_acc: 0.6249\n",
      "Epoch 32/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1405 - acc: 0.9797 - val_loss: 3.9886 - val_acc: 0.6317\n",
      "Epoch 33/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0823 - acc: 0.9837 - val_loss: 3.8416 - val_acc: 0.6188\n",
      "Epoch 34/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1122 - acc: 0.9785 - val_loss: 3.3470 - val_acc: 0.6366\n",
      "Epoch 35/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0901 - acc: 0.9858 - val_loss: 3.9331 - val_acc: 0.6083\n",
      "Epoch 36/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0838 - acc: 0.9852 - val_loss: 3.4855 - val_acc: 0.6255\n",
      "Epoch 37/50\n",
      "3307/3307 [==============================] - 83s 25ms/step - loss: 0.0852 - acc: 0.9876 - val_loss: 3.8032 - val_acc: 0.6255\n",
      "Epoch 38/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1064 - acc: 0.9849 - val_loss: 3.9348 - val_acc: 0.6372\n",
      "Epoch 39/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1241 - acc: 0.9822 - val_loss: 4.0701 - val_acc: 0.6262\n",
      "Epoch 40/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0753 - acc: 0.9867 - val_loss: 4.0182 - val_acc: 0.6262\n",
      "Epoch 41/50\n",
      "3307/3307 [==============================] - 83s 25ms/step - loss: 0.0964 - acc: 0.9819 - val_loss: 3.5902 - val_acc: 0.6280\n",
      "Epoch 42/50\n",
      "3307/3307 [==============================] - 83s 25ms/step - loss: 0.0947 - acc: 0.9855 - val_loss: 3.6392 - val_acc: 0.6298\n",
      "Epoch 43/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0823 - acc: 0.9879 - val_loss: 3.9852 - val_acc: 0.6126\n",
      "Epoch 44/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1010 - acc: 0.9837 - val_loss: 3.8588 - val_acc: 0.6311\n",
      "Epoch 45/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.1152 - acc: 0.9791 - val_loss: 3.7925 - val_acc: 0.6274\n",
      "Epoch 46/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0526 - acc: 0.9891 - val_loss: 4.2254 - val_acc: 0.6139\n",
      "Epoch 47/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0728 - acc: 0.9846 - val_loss: 3.8169 - val_acc: 0.6433\n",
      "Epoch 48/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0834 - acc: 0.9864 - val_loss: 3.4094 - val_acc: 0.6304\n",
      "Epoch 49/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0906 - acc: 0.9858 - val_loss: 3.9761 - val_acc: 0.6139\n",
      "Epoch 50/50\n",
      "3307/3307 [==============================] - 84s 25ms/step - loss: 0.0992 - acc: 0.9840 - val_loss: 3.5461 - val_acc: 0.6397\n"
     ]
    }
   ],
   "source": [
    "# model3: attention decoder\n",
    "hist3 = model3.fit(x_train_speech, Y, batch_size=32, epochs=50, verbose=1, shuffle = False, \n",
    "                 validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6352977286598447 0.6580724367120648\n"
     ]
    }
   ],
   "source": [
    "acc3 = hist3.history['val_acc']\n",
    "print(np.mean(acc3), max(acc3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
